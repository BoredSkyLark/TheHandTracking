diff --git a/hand_skeleton_tracker.py b/hand_skeleton_tracker.py
new file mode 100644
index 0000000000000000000000000000000000000000..eb9ec68f191e05d98bf96f3b103db6df5936f050
--- /dev/null
+++ b/hand_skeleton_tracker.py
@@ -0,0 +1,251 @@
+"""Hand skeleton tracking script using MediaPipe and OpenCV.
+
+This module captures frames from a webcam, runs MediaPipe Hands to detect
+hand landmarks, and renders a skeleton-style overlay comparable to the
+Leap Motion visualizer. The script can be executed directly, and exposes a
+`HandSkeletonTracker` class that may be imported elsewhere.
+"""
+
+from __future__ import annotations
+
+import argparse
+import math
+from dataclasses import dataclass
+from typing import Iterable, List, Optional, Tuple
+
+import cv2
+import mediapipe as mp
+import numpy as np
+
+
+# MediaPipe hands utilities and drawing helpers.
+MP_HANDS = mp.solutions.hands
+
+
+@dataclass
+class Landmark:
+    """Normalized landmark coordinates and visibility."""
+
+    x: float
+    y: float
+    z: float
+    visibility: float
+
+    @classmethod
+    def from_mp_landmark(cls, landmark: mp.framework.formats.landmark_pb2.NormalizedLandmark) -> "Landmark":
+        """Create from a MediaPipe landmark."""
+
+        return cls(
+            x=landmark.x,
+            y=landmark.y,
+            z=landmark.z,
+            visibility=getattr(landmark, "visibility", 1.0),
+        )
+
+
+class HandSkeletonTracker:
+    """Video-based tracker that renders a hand skeleton overlay."""
+
+    def __init__(
+        self,
+        max_num_hands: int = 2,
+        min_detection_confidence: float = 0.5,
+        min_tracking_confidence: float = 0.5,
+    ) -> None:
+        self._hands = MP_HANDS.Hands(
+            static_image_mode=False,
+            max_num_hands=max_num_hands,
+            min_detection_confidence=min_detection_confidence,
+            min_tracking_confidence=min_tracking_confidence,
+            model_complexity=1,
+            smooth_landmarks=True,
+        )
+
+    def __enter__(self) -> "HandSkeletonTracker":  # pragma: no cover - context manager convenience
+        return self
+
+    def __exit__(self, exc_type, exc, exc_tb) -> None:  # pragma: no cover - context manager convenience
+        self.close()
+
+    def close(self) -> None:
+        """Release MediaPipe resources."""
+
+        self._hands.close()
+
+    def process(self, frame: np.ndarray) -> Tuple[np.ndarray, List[List[Landmark]]]:
+        """Run hand landmark detection and draw the skeleton.
+
+        Args:
+            frame: BGR image captured from OpenCV.
+
+        Returns:
+            A tuple containing the annotated frame (BGR) and a list of
+            landmarks per detected hand.
+        """
+
+        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
+        rgb_frame.flags.writeable = False
+        results = self._hands.process(rgb_frame)
+
+        landmarks_per_hand: List[List[Landmark]] = []
+        if results.multi_hand_landmarks:
+            for hand_landmarks in results.multi_hand_landmarks:
+                landmarks = [Landmark.from_mp_landmark(lm) for lm in hand_landmarks.landmark]
+                landmarks_per_hand.append(landmarks)
+
+                self._draw_hand_skeleton(frame, landmarks)
+
+        return frame, landmarks_per_hand
+
+    def _draw_hand_skeleton(self, frame: np.ndarray, landmarks: Iterable[Landmark]) -> None:
+        """Draw a skeleton overlay for one hand."""
+
+        image_height, image_width = frame.shape[:2]
+        points = [self._normalized_to_pixel_coordinates(lm, image_width, image_height) for lm in landmarks]
+
+        # Draw palm connections using MediaPipe defaults for consistency.
+        for start_idx, end_idx in MP_HANDS.HAND_CONNECTIONS:
+            start_point = points[start_idx]
+            end_point = points[end_idx]
+            if start_point is None or end_point is None:
+                continue
+            cv2.line(frame, start_point, end_point, (0, 255, 0), 2, cv2.LINE_AA)
+
+        # Draw joints as circles with depth-sensitive radius and color.
+        for idx, (landmark, point) in enumerate(zip(landmarks, points)):
+            if point is None:
+                continue
+
+            depth = landmark.z
+            radius = self._depth_to_radius(depth)
+            color = self._depth_to_color(depth)
+
+            cv2.circle(frame, point, radius, color, -1, cv2.LINE_AA)
+            cv2.putText(
+                frame,
+                str(idx),
+                (point[0] + 4, point[1] - 4),
+                cv2.FONT_HERSHEY_SIMPLEX,
+                0.35,
+                (255, 255, 255),
+                1,
+                cv2.LINE_AA,
+            )
+
+    @staticmethod
+    def _normalized_to_pixel_coordinates(
+        landmark: Landmark, image_width: int, image_height: int
+    ) -> Optional[Tuple[int, int]]:
+        if landmark.visibility < 0.5:
+            return None
+
+        x_px = min(math.floor(landmark.x * image_width), image_width - 1)
+        y_px = min(math.floor(landmark.y * image_height), image_height - 1)
+        if x_px < 0 or y_px < 0:
+            return None
+        return x_px, y_px
+
+    @staticmethod
+    def _depth_to_radius(depth: float, base_radius: int = 6) -> int:
+        """Map depth (z) to a drawing radius."""
+
+        radius = base_radius + int(max(-depth, 0.0) * 10)
+        return max(2, min(radius, 12))
+
+    @staticmethod
+    def _depth_to_color(depth: float) -> Tuple[int, int, int]:
+        """Map depth to a pseudo-3D color."""
+
+        depth_clamped = np.clip(-depth * 150, -50, 255)
+        blue = int(np.interp(depth_clamped, [-50, 255], [50, 255]))
+        red = int(np.interp(depth_clamped, [-50, 255], [255, 50]))
+        return blue, 128, red
+
+
+def parse_args(args: Optional[Iterable[str]] = None) -> argparse.Namespace:
+    """Parse command-line arguments."""
+
+    parser = argparse.ArgumentParser(description="Hand skeleton tracking demo")
+    parser.add_argument("--camera", type=int, default=0, help="Index of the camera to use.")
+    parser.add_argument("--max-hands", type=int, default=2, help="Maximum number of hands to track.")
+    parser.add_argument(
+        "--min-detection-confidence",
+        type=float,
+        default=0.6,
+        help="Minimum confidence required for hand detection.",
+    )
+    parser.add_argument(
+        "--min-tracking-confidence",
+        type=float,
+        default=0.6,
+        help="Minimum confidence required for landmark tracking.",
+    )
+    return parser.parse_args(args=args)
+
+
+def main() -> None:
+    """Entrypoint for running the tracker interactively."""
+
+    args = parse_args()
+    cap = cv2.VideoCapture(args.camera)
+    if not cap.isOpened():
+        raise RuntimeError(f"Unable to open camera index {args.camera}")
+
+    with HandSkeletonTracker(
+        max_num_hands=args.max_hands,
+        min_detection_confidence=args.min_detection_confidence,
+        min_tracking_confidence=args.min_tracking_confidence,
+    ) as tracker:
+        while True:
+            success, frame = cap.read()
+            if not success:
+                print("Failed to read frame from camera. Exiting...")
+                break
+
+            annotated_frame, landmarks = tracker.process(frame)
+            self_info = _format_info_text(landmarks)
+            _draw_overlay_text(annotated_frame, self_info)
+
+            cv2.imshow("Hand Skeleton Tracker", annotated_frame)
+            key = cv2.waitKey(1) & 0xFF
+            if key in (27, ord("q")):
+                break
+
+    cap.release()
+    cv2.destroyAllWindows()
+
+
+def _format_info_text(landmarks_per_hand: List[List[Landmark]]) -> str:
+    """Create informational text about detected hands."""
+
+    if not landmarks_per_hand:
+        return "Hands detected: 0"
+
+    info_lines = [f"Hands detected: {len(landmarks_per_hand)}"]
+    for idx, landmarks in enumerate(landmarks_per_hand, start=1):
+        wrist = landmarks[MP_HANDS.HandLandmark.WRIST.value]
+        info_lines.append(
+            f"Hand {idx}: wrist=({wrist.x:.2f}, {wrist.y:.2f}, {wrist.z:.2f}), visibility={wrist.visibility:.2f}"
+        )
+    return " | ".join(info_lines)
+
+
+def _draw_overlay_text(frame: np.ndarray, text: str) -> None:
+    """Draw HUD-like text at the top-left corner of the frame."""
+
+    cv2.rectangle(frame, (0, 0), (frame.shape[1], 30), (0, 0, 0), thickness=-1)
+    cv2.putText(
+        frame,
+        text,
+        (10, 20),
+        cv2.FONT_HERSHEY_SIMPLEX,
+        0.5,
+        (255, 255, 255),
+        1,
+        cv2.LINE_AA,
+    )
+
+
+if __name__ == "__main__":
+    main()
+
